{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x998efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(\"training_history.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "plt.plot(b[0],b[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class FaceDateSet(Dataset):\n",
    "    \"\"\"lfw face data set.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split_file, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split_file = split_file\n",
    "        self.transform = transform\n",
    "        self.img_paths = self.parse_files()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get items from path here\n",
    "        img1_path = os.path.join(self.root_dir, self.img_paths[idx][0])\n",
    "        img2_path = os.path.join(self.root_dir, self.img_paths[idx][1])\n",
    "        img_label = map(float,self.img_paths[idx][2])\n",
    "        img_label = torch.from_numpy(np.array(img_label)).float()\n",
    "        img1 = Image.open(img1_path)\n",
    "        img2 = Image.open(img2_path)\n",
    "        img1 = img1.convert('RGB')\n",
    "        img2 = img2.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        sample = {'img1': img1, 'img2': img2, 'label': img_label}\n",
    "        return sample\n",
    "\n",
    "    def parse_files(self):\n",
    "        img_paths = []\n",
    "        with open(self.split_file) as f:\n",
    "            img_paths = f.readlines()\n",
    "        img_paths = [x.split() for x in img_paths]\n",
    "        return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define deep neural network\n",
    "class SiameseNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,stride=2),\n",
    "            nn.Conv2d(64,128,5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,stride=2),\n",
    "            nn.Conv2d(128,256,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2,stride=2),\n",
    "            nn.Conv2d(256,512,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(131072,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(1024),\n",
    "        )\n",
    "\n",
    "        self.nn3 = nn.Sequential(\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def net_forward(self,x):\n",
    "        temp = self.nn1(x)\n",
    "        temp = temp.view(temp.size()[0], -1)\n",
    "        output = self.nn2(temp)\n",
    "        return output\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        output1 = self.net_forward(x1)\n",
    "        output2 = self.net_forward(x2)\n",
    "        output12 = torch.cat((output1,output2),1)\n",
    "        output = self.nn3(output12)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Loss 0.090949\n",
      "Batch 110 Loss 0.725484\n",
      "Batch 220 Loss 0.017345\n",
      "Batch 330 Loss 0.699157\n",
      "Batch 440 Loss 0.026592\n",
      "Average BCE loss on training data is:  0.155582274041 \n",
      " Prediction accuracy is:  Variable containing:\n",
      " 0.9377\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_dir = './model_best2.pth.tar'\n",
    "net = SiameseNet().cuda()\n",
    "net.load_state_dict(torch.load(weights_dir))\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Testing on the training data\n",
    "data_trans1 = transforms.Compose([transforms.Scale((128,128)),transforms.ToTensor()])\n",
    "face_test1 = FaceDateSet(root_dir='lfw', split_file='train.txt', transform = data_trans1)\n",
    "test1_loader = DataLoader(face_test1, batch_size=4, shuffle=False)\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "\n",
    "for batch_idx, batch_sample in enumerate(test1_loader):\n",
    "    img1 = batch_sample['img1']\n",
    "    img2 = batch_sample['img2']\n",
    "    label = batch_sample['label']\n",
    "    img1, img2, y = Variable(img1, volatile=True).cuda(), Variable(img2, volatile=True).cuda(), Variable(label,volatile=True).cuda()\n",
    "    y_pred = net(img1, img2)\n",
    "    bce_loss = loss_fn(y_pred, y)\n",
    "    y_pred_round = torch.round(y_pred)\n",
    "    if batch_idx % int(len(face_test1)/20) == 0:\n",
    "        print \"Batch %d Loss %f\" % (batch_idx, bce_loss.data[0])\n",
    "    total_loss += bce_loss.data[0]\n",
    "    total_correct += (y_pred_round.view(-1) == y.view(-1)).sum().float()\n",
    "    \n",
    "mean_loss = total_loss / (float(len(face_test1)) / 4.0) \n",
    "mean_correct = total_correct / float(len(face_test1))\n",
    "print \"Average BCE loss on training data is: \", mean_loss, \"\\n Prediction accuracy is: \", mean_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Loss 0.463303\n",
      "Batch 50 Loss 1.497920\n",
      "Batch 100 Loss 0.668122\n",
      "Batch 150 Loss 0.680550\n",
      "Batch 200 Loss 0.763543\n",
      "Average BCE loss on test data is:  0.79564036119 \n",
      " Prediction accuracy is:  Variable containing:\n",
      " 0.5120\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_dir = './model_best2.pth.tar'\n",
    "net = SiameseNet().cuda()\n",
    "net.load_state_dict(torch.load(weights_dir))\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Testing on the training data\n",
    "data_trans2 = transforms.Compose([transforms.Scale((128,128)),transforms.ToTensor()])\n",
    "face_test2 = FaceDateSet(root_dir='lfw', split_file='test.txt', transform = data_trans2)\n",
    "test2_loader = DataLoader(face_test2, batch_size=4, shuffle=False)\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "\n",
    "for batch_idx, batch_sample in enumerate(test2_loader):\n",
    "    img1 = batch_sample['img1']\n",
    "    img2 = batch_sample['img2']\n",
    "    label = batch_sample['label']\n",
    "    img1, img2, y = Variable(img1, volatile=True).cuda(), Variable(img2, volatile=True).cuda(), Variable(label,volatile=True).cuda()\n",
    "    y_pred = net(img1, img2)\n",
    "    bce_loss = loss_fn(y_pred, y)\n",
    "    y_pred_round = torch.round(y_pred)\n",
    "    if batch_idx % int(len(face_test2)/20) == 0:\n",
    "        print \"Batch %d Loss %f\" % (batch_idx, bce_loss.data[0])\n",
    "    total_loss += bce_loss.data[0]\n",
    "    total_correct += (y_pred_round.view(-1) == y.view(-1)).sum().float()\n",
    "    \n",
    "mean_loss = total_loss / (float(len(face_test2)) / 4.0) \n",
    "mean_correct = total_correct / float(len(face_test2))\n",
    "print \"Average BCE loss on test data is: \", mean_loss, \"\\n Prediction accuracy is: \", mean_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([transforms.Scale((128,128)),transforms.ToTensor()])\n",
    "face_train = FaceDateSet(root_dir='lfw', split_file='train.txt',transform = data_trans)\n",
    "train_loader = DataLoader(face_train, batch_size=8, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img2': \n",
      "( 0 , 0 ,.,.) = \n",
      "  0.9333  0.9255  0.9216  ...   0.9490  0.9490  0.9451\n",
      "  0.9137  0.9294  0.9216  ...   0.9490  0.9451  0.9412\n",
      "  0.8627  0.9333  0.9373  ...   0.9529  0.9490  0.9490\n",
      "           ...             ⋱             ...          \n",
      "  0.4784  0.5098  0.5176  ...   0.5255  0.5333  0.5137\n",
      "  0.3961  0.4549  0.4745  ...   0.5569  0.5333  0.4627\n",
      "  0.4196  0.4392  0.4745  ...   0.6157  0.5255  0.4431\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.9412  0.9333  0.9294  ...   0.9529  0.9529  0.9490\n",
      "  0.9216  0.9373  0.9294  ...   0.9529  0.9490  0.9451\n",
      "  0.8706  0.9412  0.9451  ...   0.9569  0.9529  0.9529\n",
      "           ...             ⋱             ...          \n",
      "  0.5098  0.5373  0.5373  ...   0.5412  0.5490  0.5333\n",
      "  0.4392  0.4941  0.5020  ...   0.5725  0.5490  0.4863\n",
      "  0.4706  0.4824  0.5059  ...   0.6314  0.5451  0.4667\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.9216  0.9137  0.9098  ...   0.9333  0.9333  0.9294\n",
      "  0.9020  0.9176  0.9059  ...   0.9333  0.9294  0.9255\n",
      "  0.8510  0.9216  0.9216  ...   0.9451  0.9333  0.9333\n",
      "           ...             ⋱             ...          \n",
      "  0.5451  0.5686  0.5725  ...   0.5843  0.5922  0.5804\n",
      "  0.4824  0.5333  0.5412  ...   0.6157  0.5922  0.5333\n",
      "  0.5216  0.5216  0.5451  ...   0.6745  0.5882  0.5137\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.1804  0.1804  0.1843  ...   0.1412  0.1333  0.1255\n",
      "  0.1804  0.1804  0.1843  ...   0.1412  0.1333  0.1255\n",
      "  0.1804  0.1804  0.1843  ...   0.1412  0.1333  0.1255\n",
      "           ...             ⋱             ...          \n",
      "  0.1451  0.1412  0.2471  ...   0.0745  0.0706  0.0667\n",
      "  0.2157  0.2706  0.3922  ...   0.0902  0.0824  0.0784\n",
      "  0.3686  0.3647  0.3804  ...   0.1020  0.0980  0.0941\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.1137  0.1137  0.1176  ...   0.0784  0.0745  0.0745\n",
      "  0.1137  0.1137  0.1176  ...   0.0784  0.0745  0.0745\n",
      "  0.1137  0.1137  0.1176  ...   0.0784  0.0745  0.0745\n",
      "           ...             ⋱             ...          \n",
      "  0.1608  0.1569  0.2667  ...   0.0824  0.0745  0.0706\n",
      "  0.2392  0.2941  0.4118  ...   0.0902  0.0824  0.0824\n",
      "  0.3922  0.3882  0.4039  ...   0.1020  0.0980  0.0980\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.0118  0.0118  0.0157  ...   0.0157  0.0118  0.0118\n",
      "  0.0118  0.0118  0.0157  ...   0.0157  0.0118  0.0118\n",
      "  0.0118  0.0118  0.0157  ...   0.0157  0.0118  0.0118\n",
      "           ...             ⋱             ...          \n",
      "  0.0706  0.0667  0.1725  ...   0.0392  0.0314  0.0235\n",
      "  0.1373  0.1922  0.3137  ...   0.0431  0.0353  0.0314\n",
      "  0.2902  0.2863  0.3020  ...   0.0549  0.0471  0.0431\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.4078  0.4039  0.4039  ...   0.6196  0.6118  0.6078\n",
      "  0.4039  0.4000  0.4000  ...   0.6275  0.6196  0.6118\n",
      "  0.4000  0.3961  0.4000  ...   0.6353  0.6275  0.6196\n",
      "           ...             ⋱             ...          \n",
      "  0.0431  0.0431  0.0471  ...   0.0353  0.0431  0.1176\n",
      "  0.0431  0.0431  0.0471  ...   0.0353  0.0431  0.1137\n",
      "  0.0471  0.0471  0.0471  ...   0.0353  0.0431  0.1137\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.2745  0.2706  0.2706  ...   0.4588  0.4431  0.4314\n",
      "  0.2706  0.2667  0.2667  ...   0.4667  0.4510  0.4431\n",
      "  0.2667  0.2627  0.2667  ...   0.4745  0.4588  0.4510\n",
      "           ...             ⋱             ...          \n",
      "  0.0353  0.0353  0.0392  ...   0.0353  0.0314  0.0863\n",
      "  0.0353  0.0353  0.0392  ...   0.0353  0.0275  0.0824\n",
      "  0.0392  0.0392  0.0392  ...   0.0353  0.0275  0.0824\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.1686  0.1647  0.1608  ...   0.2784  0.2706  0.2667\n",
      "  0.1647  0.1608  0.1608  ...   0.2863  0.2824  0.2745\n",
      "  0.1608  0.1569  0.1569  ...   0.2941  0.2902  0.2824\n",
      "           ...             ⋱             ...          \n",
      "  0.0392  0.0392  0.0431  ...   0.0157  0.0039  0.0431\n",
      "  0.0392  0.0392  0.0431  ...   0.0196  0.0039  0.0392\n",
      "  0.0431  0.0431  0.0431  ...   0.0196  0.0039  0.0471\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "( 5 , 0 ,.,.) = \n",
      "  0.0784  0.0784  0.0784  ...   0.1686  0.1765  0.1765\n",
      "  0.1922  0.1961  0.1961  ...   0.4471  0.4627  0.4627\n",
      "  0.2157  0.2157  0.2196  ...   0.4784  0.5020  0.5059\n",
      "           ...             ⋱             ...          \n",
      "  0.8157  0.8235  0.8039  ...   0.8314  0.8039  0.7529\n",
      "  0.8039  0.8000  0.7804  ...   0.7961  0.7569  0.7020\n",
      "  0.7804  0.7765  0.7569  ...   0.7686  0.7137  0.6706\n",
      "\n",
      "( 5 , 1 ,.,.) = \n",
      "  0.0588  0.0588  0.0588  ...   0.1569  0.1608  0.1569\n",
      "  0.1608  0.1608  0.1608  ...   0.4275  0.4431  0.4431\n",
      "  0.1647  0.1647  0.1686  ...   0.4549  0.4745  0.4784\n",
      "           ...             ⋱             ...          \n",
      "  0.6902  0.7020  0.6980  ...   0.6784  0.6353  0.5686\n",
      "  0.6824  0.6863  0.6824  ...   0.6392  0.5804  0.5098\n",
      "  0.6588  0.6627  0.6627  ...   0.6039  0.5333  0.4784\n",
      "\n",
      "( 5 , 2 ,.,.) = \n",
      "  0.0314  0.0314  0.0314  ...   0.1255  0.1294  0.1255\n",
      "  0.0941  0.0941  0.0941  ...   0.3255  0.3412  0.3412\n",
      "  0.0706  0.0706  0.0745  ...   0.3137  0.3333  0.3373\n",
      "           ...             ⋱             ...          \n",
      "  0.5020  0.5333  0.5608  ...   0.4588  0.3922  0.3137\n",
      "  0.4863  0.5137  0.5412  ...   0.4000  0.3216  0.2431\n",
      "  0.4627  0.4824  0.5216  ...   0.3608  0.2667  0.2039\n",
      "      ⋮  \n",
      "\n",
      "( 6 , 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0078  0.0078  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0078  0.0078  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0078  0.0078  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 6 , 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0039  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0039  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0039  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 6 , 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0078  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0078  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0078  ...   0.0000  0.0000  0.0000\n",
      "      ⋮  \n",
      "\n",
      "( 7 , 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0941  0.0902  0.0824  ...   0.5529  0.5765  0.6039\n",
      "  0.0980  0.0863  0.0863  ...   0.5529  0.5686  0.6039\n",
      "  0.0941  0.0902  0.0902  ...   0.5569  0.5647  0.6039\n",
      "\n",
      "( 7 , 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.1647  0.1608  0.1529  ...   0.3529  0.3765  0.3961\n",
      "  0.1647  0.1569  0.1569  ...   0.3529  0.3686  0.3961\n",
      "  0.1647  0.1608  0.1608  ...   0.3569  0.3608  0.3961\n",
      "\n",
      "( 7 , 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.1725  0.1686  0.1608  ...   0.1843  0.2078  0.2314\n",
      "  0.1765  0.1647  0.1647  ...   0.1843  0.2000  0.2314\n",
      "  0.1725  0.1686  0.1686  ...   0.1882  0.1922  0.2314\n",
      "[torch.FloatTensor of size 8x3x128x128]\n",
      ", 'img1': \n",
      "( 0 , 0 ,.,.) = \n",
      "  0.2863  0.2863  0.2863  ...   0.3804  0.3765  0.3725\n",
      "  0.2745  0.2863  0.2902  ...   0.3765  0.3725  0.3725\n",
      "  0.2745  0.2902  0.2941  ...   0.3765  0.3804  0.3843\n",
      "           ...             ⋱             ...          \n",
      "  0.7294  0.7294  0.7255  ...   0.6980  0.6941  0.6863\n",
      "  0.7216  0.6980  0.6784  ...   0.6980  0.7020  0.7098\n",
      "  0.6745  0.6510  0.6431  ...   0.6941  0.7020  0.7137\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.2157  0.2157  0.2157  ...   0.2667  0.2588  0.2510\n",
      "  0.2039  0.2157  0.2196  ...   0.2588  0.2549  0.2471\n",
      "  0.2039  0.2196  0.2235  ...   0.2510  0.2510  0.2510\n",
      "           ...             ⋱             ...          \n",
      "  0.7294  0.7294  0.7294  ...   0.6863  0.6784  0.6667\n",
      "  0.7020  0.6745  0.6588  ...   0.6980  0.6941  0.6980\n",
      "  0.6314  0.6039  0.5922  ...   0.6980  0.7020  0.7059\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.0667  0.0667  0.0667  ...   0.0275  0.0314  0.0353\n",
      "  0.0549  0.0667  0.0706  ...   0.0157  0.0196  0.0196\n",
      "  0.0549  0.0706  0.0745  ...   0.0039  0.0078  0.0118\n",
      "           ...             ⋱             ...          \n",
      "  0.7373  0.7294  0.7176  ...   0.6118  0.5961  0.5804\n",
      "  0.6980  0.6667  0.6392  ...   0.6471  0.6392  0.6314\n",
      "  0.6196  0.5922  0.5725  ...   0.6667  0.6588  0.6549\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.1294  0.1333  0.1333  ...   0.1490  0.1412  0.1451\n",
      "  0.2196  0.2314  0.2314  ...   0.2588  0.2431  0.2353\n",
      "  0.2235  0.2353  0.2314  ...   0.2667  0.2471  0.2471\n",
      "           ...             ⋱             ...          \n",
      "  0.1647  0.1608  0.1725  ...   0.1137  0.1059  0.1020\n",
      "  0.1725  0.1804  0.1804  ...   0.1098  0.1059  0.1020\n",
      "  0.1765  0.1882  0.2000  ...   0.0980  0.1059  0.1059\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.1137  0.1176  0.1176  ...   0.1216  0.1216  0.1255\n",
      "  0.2078  0.2235  0.2235  ...   0.2353  0.2235  0.2157\n",
      "  0.2157  0.2275  0.2235  ...   0.2431  0.2235  0.2275\n",
      "           ...             ⋱             ...          \n",
      "  0.1922  0.1882  0.2078  ...   0.1686  0.1608  0.1569\n",
      "  0.2000  0.2078  0.2118  ...   0.1647  0.1608  0.1569\n",
      "  0.2039  0.2157  0.2353  ...   0.1529  0.1608  0.1608\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.1294  0.1373  0.1412  ...   0.1373  0.1373  0.1490\n",
      "  0.2275  0.2431  0.2431  ...   0.2510  0.2431  0.2392\n",
      "  0.2392  0.2471  0.2431  ...   0.2588  0.2392  0.2510\n",
      "           ...             ⋱             ...          \n",
      "  0.2314  0.2275  0.2431  ...   0.2039  0.1961  0.1922\n",
      "  0.2392  0.2471  0.2471  ...   0.2000  0.1961  0.1922\n",
      "  0.2431  0.2549  0.2706  ...   0.1882  0.1961  0.1961\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.5098  0.5098  0.5098  ...   0.4902  0.4902  0.4902\n",
      "  0.5137  0.5137  0.5137  ...   0.4902  0.4902  0.4902\n",
      "  0.5137  0.5137  0.5137  ...   0.4902  0.4902  0.4902\n",
      "           ...             ⋱             ...          \n",
      "  0.0745  0.0784  0.0745  ...   0.1059  0.1020  0.1059\n",
      "  0.0706  0.0745  0.0745  ...   0.1020  0.0980  0.1059\n",
      "  0.0706  0.0745  0.0745  ...   0.0980  0.0980  0.1020\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.2941  0.2941  0.2941  ...   0.2902  0.2902  0.2902\n",
      "  0.2902  0.2902  0.2902  ...   0.2902  0.2902  0.2902\n",
      "  0.2902  0.2902  0.2902  ...   0.2902  0.2902  0.2902\n",
      "           ...             ⋱             ...          \n",
      "  0.0667  0.0706  0.0667  ...   0.0902  0.0863  0.0902\n",
      "  0.0627  0.0667  0.0667  ...   0.0863  0.0824  0.0902\n",
      "  0.0627  0.0667  0.0667  ...   0.0824  0.0824  0.0863\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.2157  0.2157  0.2157  ...   0.2157  0.2157  0.2157\n",
      "  0.2157  0.2157  0.2157  ...   0.2157  0.2157  0.2157\n",
      "  0.2157  0.2157  0.2157  ...   0.2157  0.2157  0.2157\n",
      "           ...             ⋱             ...          \n",
      "  0.0784  0.0824  0.0784  ...   0.0941  0.0902  0.0941\n",
      "  0.0745  0.0784  0.0784  ...   0.0902  0.0863  0.0941\n",
      "  0.0745  0.0784  0.0784  ...   0.0863  0.0863  0.0902\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "( 5 , 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.4667  0.4824  0.5098  ...   0.6549  0.6549  0.6549\n",
      "  0.4549  0.4667  0.4941  ...   0.6627  0.6667  0.6745\n",
      "  0.4471  0.4706  0.4902  ...   0.6588  0.6667  0.6784\n",
      "\n",
      "( 5 , 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.3529  0.3647  0.3882  ...   0.4627  0.4706  0.4745\n",
      "  0.3294  0.3451  0.3608  ...   0.4706  0.4824  0.4902\n",
      "  0.3176  0.3333  0.3490  ...   0.4667  0.4824  0.4980\n",
      "\n",
      "( 5 , 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.2706  0.2824  0.2941  ...   0.3961  0.4039  0.4118\n",
      "  0.2510  0.2627  0.2745  ...   0.4039  0.4118  0.4275\n",
      "  0.2392  0.2549  0.2627  ...   0.4000  0.4118  0.4353\n",
      "      ⋮  \n",
      "\n",
      "( 6 , 0 ,.,.) = \n",
      "  0.2314  0.2275  0.2275  ...   0.4000  0.4118  0.4235\n",
      "  0.2314  0.2314  0.2353  ...   0.4000  0.4118  0.4235\n",
      "  0.2353  0.2471  0.2549  ...   0.4000  0.4118  0.4235\n",
      "           ...             ⋱             ...          \n",
      "  0.0863  0.0980  0.1020  ...   0.3216  0.3294  0.3294\n",
      "  0.0863  0.0980  0.1020  ...   0.3216  0.3294  0.3333\n",
      "  0.0863  0.0941  0.0980  ...   0.3137  0.3255  0.3294\n",
      "\n",
      "( 6 , 1 ,.,.) = \n",
      "  0.1412  0.1373  0.1412  ...   0.3725  0.3843  0.3961\n",
      "  0.1412  0.1412  0.1490  ...   0.3725  0.3843  0.3961\n",
      "  0.1451  0.1569  0.1686  ...   0.3725  0.3843  0.3961\n",
      "           ...             ⋱             ...          \n",
      "  0.0824  0.0941  0.0980  ...   0.2980  0.3059  0.3059\n",
      "  0.0863  0.0980  0.1020  ...   0.2980  0.3098  0.3098\n",
      "  0.0863  0.0941  0.0980  ...   0.2980  0.3098  0.3137\n",
      "\n",
      "( 6 , 2 ,.,.) = \n",
      "  0.0745  0.0667  0.0549  ...   0.3412  0.3529  0.3647\n",
      "  0.0745  0.0706  0.0627  ...   0.3412  0.3529  0.3647\n",
      "  0.0784  0.0863  0.0863  ...   0.3412  0.3529  0.3647\n",
      "           ...             ⋱             ...          \n",
      "  0.1373  0.1490  0.1529  ...   0.2510  0.2588  0.2588\n",
      "  0.1333  0.1451  0.1490  ...   0.2510  0.2627  0.2627\n",
      "  0.1294  0.1412  0.1451  ...   0.2510  0.2627  0.2667\n",
      "      ⋮  \n",
      "\n",
      "( 7 , 0 ,.,.) = \n",
      "  0.0078  0.0078  0.0078  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.1059  0.1059  0.1059  ...   0.1843  0.2157  0.2314\n",
      "  0.1059  0.1059  0.1059  ...   0.2157  0.2275  0.2353\n",
      "  0.1059  0.1059  0.1059  ...   0.2314  0.2353  0.2353\n",
      "\n",
      "( 7 , 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0039  0.0039  0.0039  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0039  0.0039  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0745  0.0745  0.0745  ...   0.1569  0.1804  0.1961\n",
      "  0.0745  0.0745  0.0745  ...   0.1804  0.1922  0.1961\n",
      "  0.0745  0.0745  0.0745  ...   0.1961  0.1961  0.1961\n",
      "\n",
      "( 7 , 2 ,.,.) = \n",
      "  0.0039  0.0039  0.0039  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0039  0.0039  0.0039  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.1608  0.1608  0.1647  ...   0.1647  0.1922  0.2078\n",
      "  0.1569  0.1569  0.1569  ...   0.1843  0.1961  0.2039\n",
      "  0.1569  0.1569  0.1569  ...   0.2000  0.2000  0.2000\n",
      "[torch.FloatTensor of size 8x3x128x128]\n",
      ", 'label': \n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "[torch.FloatTensor of size 8x1]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "iterrr = iter(train_loader)\n",
    "print next(iterrr)\n",
    "# print face_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0 Loss 0.569435\n"
     ]
    }
   ],
   "source": [
    "# Training the net\n",
    "net = SiameseNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-6)\n",
    "loss_fn = nn.BCELoss()\n",
    "total_epoch = 30 \n",
    "for epoch in range(total_epoch):\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        img1 = batch_sample['img1']\n",
    "        img2 = batch_sample['img2']\n",
    "        label = batch_sample['label']\n",
    "        # label = label.view(label.numel(),-1)\n",
    "        img1, img2, y = Variable(img1), Variable(img2), Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = net(img1, img2)\n",
    "        bce_loss = loss_fn(y_pred, y)\n",
    "        bce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print \"Epoch %d, Batch %d Loss %f\" % (epoch, batch_idx, bce_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0 Loss 0.692584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-149cf56fb08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print y_pred, type(y_pred), y, type(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbce_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = SiameseNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-6)\n",
    "loss_fn = nn.BCELoss()\n",
    "total_epoch = 2\n",
    "for epoch in range(total_epoch):\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        img1 = batch_sample['img1']\n",
    "        img2 = batch_sample['img2']\n",
    "        label = batch_sample['label'].float()\n",
    "        label = label.view(label.numel(),-1)\n",
    "        img1, img2, y = Variable(img1), Variable(img2), Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = net(img1, img2)\n",
    "        bce_loss = loss_fn(y_pred, y)\n",
    "        bce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print \"Epoch %d, Batch %d Loss %f\" % (epoch, batch_idx, bce_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "<torch.autograd.function.AddConstantBackward object at 0x7fbf1f2a2620>\n",
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2),requires_grad=True)\n",
    "print(x)\n",
    "y = x+2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-da3fe7aef59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model_best.pth.tar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[0;32m--> 350\u001b[0;31m                     data_type(size), location)\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise RuntimeError(\n\u001b[1;32m     83\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "weights_dir = \"./model_best.pth.tar\"\n",
    "net = SiameseNet()\n",
    "net.load_state_dict(torch.load(weights_dir))\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Testing on the training data\n",
    "data_trans1 = transforms.Compose([transforms.ToPILImage(),transforms.Scale((128,128)),transforms.ToTensor()])\n",
    "face_test1 = FaceDateSet(root_dir='lfw', split_file='train.txt', transform = data_trans1)\n",
    "test1_loader = DataLoader(face_test1, batch_size=1, shuffle=False)\n",
    "total_loss = 0.0\n",
    "for batch_idx, batch_sample in enumerate(test1_loader):\n",
    "    img1 = batch_sample['img1']\n",
    "    img2 = batch_sample['img2']\n",
    "    label = batch_sample['label'].float()\n",
    "    label = label.view(label.numel(),-1)\n",
    "    img1, img2, y = Variable(img1), Variable(img2), Variable(label)\n",
    "    y_pred = net(img1, img2)\n",
    "    bce_loss = loss_fn(y_pred, y)\n",
    "    if batch_idx % int(len(face_test1)/10) == 0:\n",
    "        print \"Batch %d Loss %f\" % (batch_idx, bce_loss.data[0])\n",
    "    total_loss += bce_loss.data[0]\n",
    "mean_loss = total_loss / float(len(face_test1))\n",
    "print \"Average BCE loss on training data is: \", mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-06 *\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  3.3438  0.0000\n",
      "  3.2986  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-06 *\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  6.6877  0.0000\n",
      "  6.5972  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.add_(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.31873886e-37   0.00000000e+00   5.07241471e-12]\n",
      " [  9.16112884e-41   4.90654739e-12   9.16112884e-41]\n",
      " [  2.37309200e-37   0.00000000e+00   2.37310276e-37]\n",
      " [  0.00000000e+00   6.68766006e-06   9.16112884e-41]\n",
      " [  6.59719444e-06   9.16112884e-41   5.06125003e-12]]\n"
     ]
    }
   ],
   "source": [
    "b = x.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
